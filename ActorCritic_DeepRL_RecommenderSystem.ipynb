{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_edited_version.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **MOVIE RECOMMENDATION SYSTEM USING DEEP REINFORCEMENT LEARNING**"
      ],
      "metadata": {
        "id": "8hvGSa4cl6n1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Team :\n",
        "\n",
        "*  18PD05 : Bharathi A\n",
        "*  18PD33 : Shreenidhi N\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-3IPTyIYykHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference : \n",
        "\n",
        "*   https://arxiv.org/pdf/1801.00209.pdf"
      ],
      "metadata": {
        "id": "S88qesH5y1oO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**1. Importing Required libraries**"
      ],
      "metadata": {
        "id": "czh7lzELzg0y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7OSkMpVrd6I",
        "outputId": "d69d8b11-bd13-4246-bcdd-3a790086cb90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6yQhnLEL-X6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/RL/Final Package')\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY9AmDMC8Ka-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcee906-91dc-45dd-e4db-118a38b272b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sxQ9H_YLmHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "098935b2-7bfb-4e84-a08a-931f758ebdd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import time\n",
        "import itertools\n",
        "import random\n",
        "import csv\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M3XsCLG88LDo",
        "outputId": "a34e6678-c2ca-455a-863c-81b7ff94d362"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W1yNQ0yMWB2"
      },
      "source": [
        "## **2. Data Extraction and Loading**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The MovieLens dataset containing a set of movie ratings from the MovieLens website is used for recommendation**"
      ],
      "metadata": {
        "id": "2s9okDQY0Z8j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaOLGkc4L8RA",
        "outputId": "64220b7c-775d-4d23-a45a-974fb66c7225"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-05-09 04:12:21--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  22.0MB/s    in 0.2s    \n",
            "\n",
            "2022-05-09 04:12:21 (22.0 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Preprocessing the MovieLens dataset**\n",
        "\n",
        "1.  Reading the dataset of user and items(movies)\n",
        "2.  Preprocess to create a row corresponding to a rate given by a user to a movie\n",
        "3.  Grouping of all ratings given by users, storing from old(historic) to latest rating based on time\n",
        "4. Spliting the data into train and test sets, users in test set are not present in the train set and vice versa. Unique users are present in both the sets.\n",
        "5. Saving the Train and Test data in the CSV format needed for further analysis. Format followed:  \n",
        "    1. rows : item_id with ratings (combined with &)\n",
        "    2. columns : state, rewards for actions, n_state"
      ],
      "metadata": {
        "id": "6YiSZsaO3MWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KBmfNzj_6tED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9vTLvM1Msfg"
      },
      "outputs": [],
      "source": [
        "class DataGenerator():\n",
        "\n",
        "\n",
        "  def __init__(self, path_to_data, path_to_item):\n",
        "    '''\n",
        "    Get the Movie lens data with the list of users, the movies(items) and their history\n",
        "    '''\n",
        "    self.data  = self.load_data(path_to_data, path_to_item)\n",
        "    self.users = self.data['userId'].unique()   \n",
        "    self.items = self.data['itemId'].unique()   \n",
        "    self.histo = self.generate_history_funtion()\n",
        "    self.train = []\n",
        "    self.test  = []\n",
        "\n",
        "  def load_data(self, path_to_data, path_to_item):\n",
        "    '''\n",
        "    Load the data\n",
        "    '''\n",
        "    data = pd.read_csv(path_to_data, sep='\\t', \n",
        "                       names=['userId', 'itemId', 'rating', 'timestamp'])\n",
        "    movie_titles = pd.read_csv(path_to_item, sep='|', names=['itemId', 'itemName'],\n",
        "                           usecols=range(2), encoding='latin-1')\n",
        "    return data.merge(movie_titles,on='itemId', how='left')\n",
        "\n",
        "\n",
        "  def generate_history_funtion(self):\n",
        "    '''\n",
        "    Group all rates given by users and store them from older to most recent based on time.\n",
        "    '''\n",
        "    historic_users = []\n",
        "    for i, u in enumerate(self.users):\n",
        "      temp = self.data[self.data['userId'] == u]\n",
        "      temp = temp.sort_values('timestamp').reset_index()\n",
        "      temp.drop('index', axis=1, inplace=True)\n",
        "      historic_users.append(temp)\n",
        "    return historic_users\n",
        "\n",
        "  def sample_history(self, user_histo, action_ratio=0.8, max_samp_by_user=5,  max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    '''\n",
        "    Making multiple samples for a given historic set, based on some number of states and actions\n",
        "    '''\n",
        "\n",
        "    n = len(user_histo)\n",
        "    sep = int(action_ratio * n)\n",
        "    nb_sample = random.randint(1, max_samp_by_user)\n",
        "    if not nb_states:\n",
        "      nb_states = [min(random.randint(1, sep), max_state) for i in range(nb_sample)]\n",
        "    if not nb_actions:\n",
        "      nb_actions = [min(random.randint(1, n - sep), max_action) for i in range(nb_sample)]\n",
        "    assert len(nb_states) == len(nb_actions), 'Given array must have the same size'\n",
        "    \n",
        "    states  = []\n",
        "    actions = []\n",
        "    \n",
        "    for i in range(len(nb_states)):\n",
        "      sample_states = user_histo.iloc[0:sep].sample(nb_states[i])\n",
        "      sample_actions = user_histo.iloc[-(n - sep):].sample(nb_actions[i])\n",
        "      \n",
        "      sample_state =  []\n",
        "      sample_action = []\n",
        "      for j in range(nb_states[i]):\n",
        "        row   = sample_states.iloc[j]\n",
        "        # FORMAT STATE\n",
        "        state = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_state.append(state)\n",
        "      \n",
        "      for j in range(nb_actions[i]):\n",
        "        row  = sample_actions.iloc[j]\n",
        "        # FORMAT ACTION\n",
        "        action = str(row.loc['itemId']) + '&' + str(row.loc['rating'])\n",
        "        sample_action.append(action)\n",
        "\n",
        "      states.append(sample_state)\n",
        "      actions.append(sample_action)\n",
        "    return states, actions\n",
        "\n",
        "  def get_train_test_split(self, test_ratio, seed=None):\n",
        "    '''\n",
        "    Create train and test datasets\n",
        "    '''\n",
        "    n = len(self.histo)\n",
        "\n",
        "    if seed is not None:\n",
        "      random.Random(seed).shuffle(self.histo)\n",
        "    else:\n",
        "      random.shuffle(self.histo)\n",
        "\n",
        "    self.train = self.histo[:int((test_ratio * n))]\n",
        "    self.test  = self.histo[int((test_ratio * n)):]\n",
        "    self.user_train = [h.iloc[0,0] for h in self.train]\n",
        "    self.user_test  = [h.iloc[0,0] for h in self.test]\n",
        "    \n",
        "\n",
        "  def write_csv(self, filename, histo_to_write, delimiter=';', action_ratio=0.8, max_samp_by_user=5, max_state=100, max_action=50, nb_states=[], nb_actions=[]):\n",
        "    \n",
        "    with open(filename, mode='w') as file:\n",
        "      f_writer = csv.writer(file, delimiter=delimiter)\n",
        "      f_writer.writerow(['state', 'action_reward', 'n_state'])\n",
        "      for user_histo in histo_to_write:\n",
        "        states, actions = self.sample_history(user_histo, action_ratio, max_samp_by_user, max_state, max_action, nb_states, nb_actions)\n",
        "        for i in range(len(states)):\n",
        "          # FORMAT STATE\n",
        "          state_str   = '|'.join(states[i])\n",
        "          # FORMAT ACTION\n",
        "          action_str  = '|'.join(actions[i])\n",
        "          # FORMAT N_STATE\n",
        "          n_state_str = state_str + '|' + action_str\n",
        "          f_writer.writerow([state_str, action_str, n_state_str])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_f4hrNiNJxr"
      },
      "source": [
        "## **3. Generating Embeddings for Movies**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Creation of Embedding vector for each movie item**\n",
        "\n",
        "\n",
        "1.   Embedding vector created for each movie based on the context\n",
        "\n",
        "\n",
        "2. The embeddings are learnt by training a sequential neural network model, where the weight of hidden states will give the output embeddings\n",
        "\n",
        "3. Training steps :\n",
        "  1. Context : a set of historic movies rated for a user with 1 random movie removed\n",
        "  2. Target : the removed movie from historic list\n",
        "\n",
        "  3. For multiple targets and its corresponding contexts, the embedding for the target movie is created\n",
        "  4. Therefore, after training,  each movie gets a corresponding vector representation based the context of occurrence\n",
        "\n",
        "4. Embeddings of each movie is obtained and saved into a file\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FDXaAKcd7MPY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImU11xhdNOSF"
      },
      "outputs": [],
      "source": [
        "class EmbeddingsGenerator:\n",
        "\n",
        "  def  __init__(self, train_users, data):\n",
        "    self.train_users = train_users\n",
        "\n",
        "    self.data = data.sort_values(by=['timestamp'])\n",
        "   \n",
        "    self.data['userId'] = self.data['userId'] - 1\n",
        "    self.data['itemId'] = self.data['itemId'] - 1\n",
        "\n",
        "    self.user_count = self.data['userId'].max() + 1\n",
        "    self.movie_count = self.data['itemId'].max() + 1\n",
        "\n",
        "    self.user_movies = {} #list of rated movies by each user\n",
        "    for userId in range(self.user_count):\n",
        "      self.user_movies[userId] = self.data[self.data.userId == userId]['itemId'].tolist()\n",
        "    self.m = self.define_model()\n",
        "\n",
        "  def define_model(self, hidden_layer_size=100):\n",
        "    # adding required layers\n",
        "    m = Sequential()\n",
        "    m.add(Dense(hidden_layer_size, input_shape=(1, self.movie_count)))\n",
        "    m.add(Dropout(0.2))\n",
        "    m.add(Dense(self.movie_count, activation='softmax'))\n",
        "    m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return m\n",
        "  \n",
        "  def generate_input(self, user_id):\n",
        "    '''\n",
        "    Returns a context and a target for the user_id\n",
        "    '''\n",
        "    user_movies_count = len(self.user_movies[user_id])\n",
        "    #picking random movie\n",
        "    random_index = np.random.randint(0, user_movies_count-1) # -1 avoids taking the last movie\n",
        "    #set target\n",
        "    target = np.zeros((1, self.movie_count))\n",
        "    target[0][self.user_movies[user_id][random_index]] = 1\n",
        "    #set context\n",
        "    context = np.zeros((1, self.movie_count))\n",
        "    context[0][self.user_movies[user_id][:random_index] + self.user_movies[user_id][random_index+1:]] = 1\n",
        "    return context, target\n",
        "\n",
        "  def train(self, nb_epochs = 300, batch_size = 10000):\n",
        "    '''\n",
        "    Trains the model from train_users's history\n",
        "    '''\n",
        "    for i in range(nb_epochs):\n",
        "      print('%d/%d' % (i+1, nb_epochs))\n",
        "      batch = [self.generate_input(user_id=np.random.choice(self.train_users) - 1) for _ in range(batch_size)]\n",
        "      X_train = np.array([b[0] for b in batch])\n",
        "      y_train = np.array([b[1] for b in batch])\n",
        "      self.m.fit(X_train, y_train, epochs=1, validation_split=0.5)\n",
        "\n",
        "  def test(self, test_users, batch_size = 100000):\n",
        "    '''\n",
        "    Returns on the test set\n",
        "    '''\n",
        "    batch_test = [self.generate_input(user_id=np.random.choice(test_users) - 1) for _ in range(batch_size)]\n",
        "    X_test = np.array([b[0] for b in batch_test])\n",
        "    y_test = np.array([b[1] for b in batch_test])\n",
        "    return self.m.evaluate(X_test, y_test)\n",
        "\n",
        "  def save_embeddings(self, file_name):\n",
        "    '''\n",
        "    Generates a csv file containg the vector embedding for each movie.\n",
        "    '''\n",
        "    inp = self.m.input                                           # input placeholder\n",
        "    outputs = [layer.output for layer in self.m.layers]          # all layer outputs\n",
        "    functor = K.function([inp, K.learning_phase()], outputs )   # evaluation function\n",
        "\n",
        "    #append embeddings to vectors\n",
        "    vectors = []\n",
        "    for movie_id in range(self.movie_count):\n",
        "      movie = np.zeros((1, 1, self.movie_count))\n",
        "      movie[0][0][movie_id] = 1\n",
        "      layer_outs = functor([movie])\n",
        "      vector = [str(v) for v in layer_outs[0][0][0]]\n",
        "      vector = '|'.join(vector)\n",
        "      vectors.append([movie_id, vector])\n",
        "\n",
        "    #saves as a csv file\n",
        "    embeddings = pd.DataFrame(vectors, columns=['item_id', 'vectors']).astype({'item_id': 'int32'})\n",
        "    embeddings.to_csv(file_name, sep=';', index=False)\n",
        "    files.download(file_name) \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings:\n",
        "  def __init__(self, item_embeddings):\n",
        "    self.item_embeddings = item_embeddings\n",
        "  \n",
        "  def size(self):\n",
        "    return self.item_embeddings.shape[1]\n",
        "  \n",
        "  def get_embedding_vector(self):\n",
        "    return self.item_embeddings\n",
        "  \n",
        "  def get_embedding(self, item_index):\n",
        "    return self.item_embeddings[item_index]\n",
        "\n",
        "  def embed(self, item_list):\n",
        "    return np.array([self.get_embedding(item) for item in item_list])"
      ],
      "metadata": {
        "id": "OBgjHWDS93CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Functions to help in loading the train and test data and embeddings saved**"
      ],
      "metadata": {
        "id": "QDAfxBwT96Xh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRxo0mjfNWa-"
      },
      "outputs": [],
      "source": [
        "def file_reading(data_path):\n",
        "  ''' Load data from train.csv or test.csv. '''\n",
        "\n",
        "  data = pd.read_csv(data_path, sep=';')\n",
        "  for col in ['state', 'n_state', 'action_reward']:\n",
        "    data[col] = [np.array([[np.int(k) for k in ee.split('&')] for ee in e.split('|')]) for e in data[col]]\n",
        "  for col in ['state', 'n_state']:\n",
        "    data[col] = [np.array([e[0] for e in l]) for l in data[col]]\n",
        "\n",
        "  data['action'] = [[e[0] for e in l] for l in data['action_reward']]\n",
        "  data['reward'] = [tuple(e[1] for e in l) for l in data['action_reward']]\n",
        "  data.drop(columns=['action_reward'], inplace=True)\n",
        "\n",
        "  return data\n",
        "\n",
        "def embeddings_reading(embeddings_path):\n",
        "  ''' Load embeddings (a vector for each item). '''\n",
        "  \n",
        "  embeddings = pd.read_csv(embeddings_path, sep=';')\n",
        "\n",
        "  return np.array([[np.float64(k) for k in e.split('|')]\n",
        "                   for e in embeddings['vectors']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mn93RKRzNXKy"
      },
      "source": [
        "## **4. Environment Simulator**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Modelling the recommendation problem as MDP : Markov Decision Process**\n",
        "1. The states, actions, rewards, trainsition probabilities, discount factor are defined\n",
        "  1. States S : The previously rated set of moveis sorted with respect to time ( old to latest ratings) for a user\n",
        "  2. Actions A : Recommend a list of items to a user at time t based on current state\n",
        "  3. Reward R : based on the rating given by the user\n",
        "  4. Transition probabilities :  the probability of state transition from st to st+1 for taking action at.\n",
        "  5. Discount factor : value lying between 0 and 1"
      ],
      "metadata": {
        "id": "UM2y58-L-jwV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn7n9BwbNeyl"
      },
      "outputs": [],
      "source": [
        "class Environment():\n",
        "\n",
        "  def __init__(self, data, embeddings, alpha, gamma, fixed_length):\n",
        "\n",
        "    self.embeddings = embeddings\n",
        "    self.embedded_data = pd.DataFrame()\n",
        "    self.embedded_data['state'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['state']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['action'] = [np.array([embeddings.get_embedding(item_id) \n",
        "      for item_id in row['action']]) for _, row in data.iterrows()]\n",
        "    self.embedded_data['reward'] = data['reward']\n",
        "\n",
        "    self.alpha = alpha # α (alpha) \n",
        "    self.gamma = gamma # Γ (Gamma) \n",
        "    self.fixed_length = fixed_length\n",
        "    self.current_state = self.reset()\n",
        "    self.groups = self.get_groups()\n",
        "\n",
        "  def reset(self):\n",
        "    self.init_state = self.embedded_data['state'].sample(1).values[0]\n",
        "    return self.init_state\n",
        "\n",
        "  def step(self, actions):\n",
        "    '''\n",
        "    Compute reward and update state \n",
        "    '''\n",
        "    # Compute overall reward r_t\n",
        "    simulated_rewards, cumulated_reward = self.simulate_rewards(self.current_state.reshape((1, -1)), actions.reshape((1, -1)))\n",
        "\n",
        "    # Set s_t+1 = s_t <=> self.current_state = self.current_state\n",
        "\n",
        "    for k in range(len(simulated_rewards)): # '12: for k = 1, K do'\n",
        "      if simulated_rewards[k] > 0: # '13: if r_t^k > 0 then'\n",
        "        # '14: Add a_t^k to the end of s_t+1'\n",
        "        self.current_state = np.append(self.current_state, [actions[k]], axis=0)\n",
        "        if self.fixed_length: # '15: Remove the first item of s_t+1'\n",
        "          self.current_state = np.delete(self.current_state, 0, axis=0)\n",
        "\n",
        "    return cumulated_reward, self.current_state\n",
        "\n",
        "  def get_groups(self):\n",
        "    ''' Calculate average state/action value for each group '''\n",
        "\n",
        "    groups = []\n",
        "    for rewards, group in self.embedded_data.groupby(['reward']):\n",
        "      size = group.shape[0]\n",
        "      states = np.array(list(group['state'].values))\n",
        "      actions = np.array(list(group['action'].values))\n",
        "      groups.append({\n",
        "        'size': size, # N_x in article\n",
        "        'rewards': rewards, # U_x in article (combination of rewards)\n",
        "        'average state': (np.sum(states / np.linalg.norm(states, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)), # s_x^-\n",
        "        'average action': (np.sum(actions / np.linalg.norm(actions, 2, axis=1)[:, np.newaxis], axis=0) / size).reshape((1, -1)) # a_x^-\n",
        "      })\n",
        "    return groups\n",
        "\n",
        "  def simulate_rewards(self, current_state, chosen_actions, reward_type='grouped cosine'):\n",
        "    '''\n",
        "    Calculate simulated rewards\n",
        "    '''\n",
        "    def cosine_state_action(s_t, a_t, s_i, a_i):\n",
        "      cosine_state = np.dot(s_t, s_i.T) / (np.linalg.norm(s_t, 2) * np.linalg.norm(s_i, 2))\n",
        "      cosine_action = np.dot(a_t, a_i.T) / (np.linalg.norm(a_t, 2) * np.linalg.norm(a_i, 2))\n",
        "      return (self.alpha * cosine_state + (1 - self.alpha) * cosine_action).reshape((1,))\n",
        "\n",
        "    if reward_type == 'normal':\n",
        "      # Calculate simulated reward \n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, row['state'], row['action'])\n",
        "        for _, row in self.embedded_data.iterrows()]\n",
        "    elif reward_type == 'grouped average':\n",
        "      # Calculate simulated reward by grouped average\n",
        "      probabilities = np.array([g['size'] for g in self.groups]) *\\\n",
        "        [(self.alpha * (np.dot(current_state, g['average state'].T) / np.linalg.norm(current_state, 2))\\\n",
        "        + (1 - self.alpha) * (np.dot(chosen_actions, g['average action'].T) / np.linalg.norm(chosen_actions, 2)))\n",
        "        for g in self.groups]\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      # Calculate simulated reward by grouped cosine\n",
        "      probabilities = [cosine_state_action(current_state, chosen_actions, g['average state'], g['average action'])\n",
        "        for g in self.groups]\n",
        "\n",
        "    # Normalizing\n",
        "    probabilities = np.array(probabilities) / sum(probabilities)\n",
        "\n",
        "    # Get most probable rewards\n",
        "    if reward_type == 'normal':\n",
        "      returned_rewards = self.embedded_data.iloc[np.argmax(probabilities)]['reward']\n",
        "    elif reward_type in ['grouped average', 'grouped cosine']:\n",
        "      returned_rewards = self.groups[np.argmax(probabilities)]['rewards']\n",
        "\n",
        "    \n",
        "    def overall_reward(rewards, gamma):\n",
        "      return np.sum([gamma**k * reward for k, reward in enumerate(rewards)])\n",
        "\n",
        "    if reward_type in ['normal', 'grouped average']:\n",
        "      # Get cumulated reward\n",
        "      cumulated_reward = overall_reward(returned_rewards, self.gamma)\n",
        "    elif reward_type == 'grouped cosine':\n",
        "      # Get probability weighted cumulated reward\n",
        "      cumulated_reward = np.sum([p * overall_reward(g['rewards'], self.gamma)\n",
        "        for p, g in zip(probabilities, self.groups)])\n",
        "\n",
        "    return returned_rewards, cumulated_reward\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYw33rm9NjRv"
      },
      "source": [
        "##**5. Actor**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**The actor framework created**\n",
        "\n",
        "2 steps in the framework : A state-specific scoring function, which rates items according to\n",
        "user’s current state; instead of just considering the average.\n",
        "1. State-specific scoring function parameter generating. \n",
        "2. action generating.\n"
      ],
      "metadata": {
        "id": "C8dAIRFgBkL8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recommendation of a list of movies. Here the output are the corresponding embeddings of the movies recommended."
      ],
      "metadata": {
        "id": "O14HzIQWC8mV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEPPMhgGNnrk"
      },
      "outputs": [],
      "source": [
        "class Actor():\n",
        "  ''' Policy function approximator '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embedding_size, tau, learning_rate, scope='actor'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.batch_size = batch_size\n",
        "    self.ra_length = ra_length\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      # Build Actor network\n",
        "      self.action_weights, self.state, self.sequence_length = self._build_net('estimator_actor')\n",
        "      self.network_params = tf.trainable_variables()\n",
        "\n",
        "      # Build target Actor network\n",
        "      self.target_action_weights, self.target_state, self.target_sequence_length = self._build_net('target_actor')\n",
        "      self.target_network_params = tf.trainable_variables()[len(self.network_params):] # TODO: why sublist [len(x):]? Maybe because its equal to network_params + target_network_params\n",
        "\n",
        "      # Initialize target network weights with network weights (θ^π′ ← θ^π)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "        \n",
        "      # Update target network weights (θ^π′ ← τθ^π + (1 − τ)θ^π′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Gradient computation from Critic's action_gradients\n",
        "      self.action_gradients = tf.placeholder(tf.float32, [None, self.action_space_size])\n",
        "      gradients = tf.gradients(tf.reshape(self.action_weights, [self.batch_size, self.action_space_size], name='42222222222'),\n",
        "                               self.network_params,\n",
        "                               self.action_gradients)\n",
        "      params_gradients = list(map(lambda x: tf.div(x, self.batch_size * self.action_space_size), gradients))\n",
        "      \n",
        "      # Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s)\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).apply_gradients(\n",
        "          zip(params_gradients, self.network_params))\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Actor network '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        x = tf.cast(x, tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      batch_range = tf.range(tf.cast(tf.shape(data)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([batch_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "     \n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      sequence_length = tf.placeholder(tf.int32, [None], 'sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.embedding_size,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      outputs, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      last_output = gather_last_output(outputs, sequence_length) \n",
        "      x = tf.keras.layers.Dense(self.ra_length * self.embedding_size)(last_output)\n",
        "      action_weights = tf.reshape(x, [-1, self.ra_length, self.embedding_size])\n",
        "\n",
        "    return action_weights, state, sequence_length\n",
        "\n",
        "  def train(self, state, sequence_length, action_gradients):\n",
        "    '''  Compute ∇_a.Q(s, a|θ^µ).∇_θ^π.f_θ^π(s). '''\n",
        "    self.sess.run(self.optimizer,\n",
        "                  feed_dict={\n",
        "                      self.state: state,\n",
        "                      self.sequence_length: sequence_length,\n",
        "                      self.action_gradients: action_gradients})\n",
        "\n",
        "  def predict(self, state, sequence_length):\n",
        "    return self.sess.run(self.action_weights,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, sequence_length):\n",
        "    return self.sess.run(self.target_action_weights,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)\n",
        "    \n",
        "  def get_recommendation_list(self, ra_length, noisy_state, embeddings, target=False):\n",
        "   \n",
        "    def get_score(weights, embedding, batch_size):\n",
        "     \n",
        "      ret = np.dot(weights, embedding.T)\n",
        "      return ret\n",
        "\n",
        "    batch_size = noisy_state.shape[0]\n",
        "\n",
        "    # Generate w_t = {w_t^1, ..., w_t^K} \n",
        "    method = self.predict_target if target else self.predict\n",
        "    weights = method(noisy_state, [ra_length] * batch_size)\n",
        "\n",
        "    # Score items \n",
        "    scores = np.array([[[get_score(weights[i][k], embedding, batch_size)\n",
        "      for embedding in embeddings.get_embedding_vector()]\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])\n",
        "\n",
        "    return np.array([[embeddings.get_embedding(np.argmax(scores[i][k]))\n",
        "      for k in range(ra_length)]\n",
        "      for i in range(batch_size)])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nT-mTv7Ns5r"
      },
      "source": [
        "##**6. Critic**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**An approximator to learn the action-value function**\n",
        "1. Necessary for the judgment of whether the\n",
        "action at generated by Actor matches the current state st\n",
        "2. Updation of parameters in the direction of improving the performance"
      ],
      "metadata": {
        "id": "BnUyTGFeDQ2w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h4XIrmbFNu2P"
      },
      "outputs": [],
      "source": [
        "class Critic():\n",
        "  ''' Value function approximator '''\n",
        "  \n",
        "  def __init__(self, sess, state_space_size, action_space_size, history_length, embedding_size, tau, learning_rate, scope='critic'):\n",
        "    self.sess = sess\n",
        "    self.state_space_size = state_space_size\n",
        "    self.action_space_size = action_space_size\n",
        "    self.history_length = history_length\n",
        "    self.embedding_size = embedding_size\n",
        "    self.tau = tau\n",
        "    self.learning_rate = learning_rate\n",
        "    self.scope = scope\n",
        "\n",
        "    with tf.variable_scope(self.scope):\n",
        "      # Build Critic network\n",
        "      self.critic_Q_value, self.state, self.action, self.sequence_length = self._build_net('estimator_critic')\n",
        "      self.network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='estimator_critic')\n",
        "\n",
        "      # Build target Critic network\n",
        "      self.target_Q_value, self.target_state, self.target_action, self.target_sequence_length = self._build_net('target_critic')\n",
        "      self.target_network_params = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='target_critic')\n",
        "\n",
        "      # Initialize target network weights with network weights (θ^µ′ ← θ^µ)\n",
        "      self.init_target_network_params = [self.target_network_params[i].assign(self.network_params[i])\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Update target network weights (θ^µ′ ← τθ^µ + (1 − τ)θ^µ′)\n",
        "      self.update_target_network_params = [self.target_network_params[i].assign(\n",
        "        tf.multiply(self.tau, self.network_params[i]) +\n",
        "        tf.multiply(1 - self.tau, self.target_network_params[i]))\n",
        "        for i in range(len(self.target_network_params))]\n",
        "\n",
        "      # Minimize MSE between Critic's and target Critic's outputed Q-values\n",
        "      self.expected_reward = tf.placeholder(tf.float32, [None, 1])\n",
        "      self.loss = tf.reduce_mean(tf.squared_difference(self.expected_reward, self.critic_Q_value))\n",
        "      self.optimizer = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss)\n",
        "\n",
        "      # Compute ∇_a.Q(s, a|θ^µ)\n",
        "      self.action_gradients = tf.gradients(self.critic_Q_value, self.action)\n",
        "\n",
        "  def _build_net(self, scope):\n",
        "    ''' Build the (target) Critic network '''\n",
        "\n",
        "    def gather_last_output(data, seq_lens):\n",
        "      def cli_value(x, v):\n",
        "        y = tf.constant(v, shape=x.get_shape(), dtype=tf.int64)\n",
        "        return tf.where(tf.greater(x, y), x, y)\n",
        "\n",
        "      this_range = tf.range(tf.cast(tf.shape(seq_lens)[0], dtype=tf.int64), dtype=tf.int64)\n",
        "      tmp_end = tf.map_fn(lambda x: cli_value(x, 0), seq_lens - 1, dtype=tf.int64)\n",
        "      indices = tf.stack([this_range, tmp_end], axis=1)\n",
        "      return tf.gather_nd(data, indices)\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "      \n",
        "      state = tf.placeholder(tf.float32, [None, self.state_space_size], 'state')\n",
        "      state_ = tf.reshape(state, [-1, self.history_length, self.embedding_size])\n",
        "      action = tf.placeholder(tf.float32, [None, self.action_space_size], 'action')\n",
        "      sequence_length = tf.placeholder(tf.int64, [None], name='critic_sequence_length')\n",
        "      cell = tf.nn.rnn_cell.GRUCell(self.history_length,\n",
        "                                    activation=tf.nn.relu,\n",
        "                                    kernel_initializer=tf.initializers.random_normal(),\n",
        "                                    bias_initializer=tf.zeros_initializer())\n",
        "      predicted_state, _ = tf.nn.dynamic_rnn(cell, state_, dtype=tf.float32, sequence_length=sequence_length)\n",
        "      predicted_state = gather_last_output(predicted_state, sequence_length)\n",
        "\n",
        "      inputs = tf.concat([predicted_state, action], axis=-1)\n",
        "      layer1 = tf.layers.Dense(32, activation=tf.nn.relu)(inputs)\n",
        "      layer2 = tf.layers.Dense(16, activation=tf.nn.relu)(layer1)\n",
        "      critic_Q_value = tf.layers.Dense(1)(layer2)\n",
        "      return critic_Q_value, state, action, sequence_length\n",
        "\n",
        "  def train(self, state, action, sequence_length, expected_reward):\n",
        "    ''' Minimize MSE between expected reward and target Critic's Q-value '''\n",
        "    return self.sess.run([self.critic_Q_value, self.loss, self.optimizer],\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length,\n",
        "                             self.expected_reward: expected_reward})\n",
        "\n",
        "  def predict(self, state, action, sequence_length):\n",
        "    ''' Returns Critic's predicted Q-value '''\n",
        "    return self.sess.run(self.critic_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})\n",
        "\n",
        "  def predict_target(self, state, action, sequence_length):\n",
        "    ''' Returns target Critic's predicted Q-value '''\n",
        "    return self.sess.run(self.target_Q_value,\n",
        "                         feed_dict={\n",
        "                             self.target_state: state,\n",
        "                             self.target_action: action,\n",
        "                             self.target_sequence_length: sequence_length})\n",
        "\n",
        "  def get_action_gradients(self, state, action, sequence_length):\n",
        "    ''' Returns ∇_a.Q(s, a|θ^µ) '''\n",
        "    return np.array(self.sess.run(self.action_gradients,\n",
        "                         feed_dict={\n",
        "                             self.state: state,\n",
        "                             self.action: action,\n",
        "                             self.sequence_length: sequence_length})[0])\n",
        "\n",
        "  def init_target_network(self):\n",
        "    self.sess.run(self.init_target_network_params)\n",
        "\n",
        "  def update_target_network(self):\n",
        "    self.sess.run(self.update_target_network_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khxQKASgN2SJ"
      },
      "source": [
        "##**7. Replay**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**The states and rewards for transitions are stored**"
      ],
      "metadata": {
        "id": "T-JgMEpTE_lf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clEPq0jYN-Pv"
      },
      "outputs": [],
      "source": [
        "class ReplayMemory():\n",
        "  ''' Replay memory D in article '''\n",
        "  \n",
        "  def __init__(self, buffer_size):\n",
        "    self.buffer_size = buffer_size\n",
        "    self.buffer = []\n",
        "\n",
        "  def add(self, state, action, reward, n_state):\n",
        "    self.buffer.append([state, action, reward, n_state])\n",
        "    if len(self.buffer) > self.buffer_size:\n",
        "      self.buffer.pop(0)\n",
        "\n",
        "  def size(self):\n",
        "    return len(self.buffer)\n",
        "\n",
        "  def sample_batch(self, batch_size):\n",
        "    return random.sample(self.buffer, batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR_iIrSLODGz"
      },
      "outputs": [],
      "source": [
        "def experience_replay(replay_memory, batch_size, actor, critic, embeddings, ra_length, state_space_size, action_space_size, discount_factor):\n",
        "  '''\n",
        "  Experience replay\n",
        "  Best Q-value, loss of Critic network\n",
        "  '''\n",
        "\n",
        "  # Sample minibatch of N transitions (s, a, r, s′) from D\n",
        "  samples = replay_memory.sample_batch(batch_size)\n",
        "  states = np.array([s[0] for s in samples])\n",
        "  actions = np.array([s[1] for s in samples])\n",
        "  rewards = np.array([s[2] for s in samples])\n",
        "  n_states = np.array([s[3] for s in samples]).reshape(-1, state_space_size)\n",
        "\n",
        "  # Generate a′ by target Actor network\n",
        "  n_actions = actor.get_recommendation_list(ra_length, states, embeddings, target=True).reshape(-1, action_space_size)\n",
        "\n",
        "  # Calculate predicted Q′(s′, a′|θ^µ′) value\n",
        "  target_Q_value = critic.predict_target(n_states, n_actions, [ra_length] * batch_size)\n",
        "\n",
        "  # Set y = r + γQ′(s′, a′|θ^µ′)\n",
        "  expected_rewards = rewards + discount_factor * target_Q_value\n",
        "  \n",
        "  # Update Critic by minimizing (y − Q(s, a|θ^µ))²\n",
        "  critic_Q_value, critic_loss, _ = critic.train(states, actions, [ra_length] * batch_size, expected_rewards)\n",
        "  \n",
        "  # Update the Actor using the sampled policy gradient\n",
        "  action_gradients = critic.get_action_gradients(states, n_actions, [ra_length] * batch_size)\n",
        "  actor.train(states, [ra_length] * batch_size, action_gradients)\n",
        "\n",
        "  # Update the Critic target networks\n",
        "  critic.update_target_network()\n",
        "\n",
        "  # Update the Actor target network\n",
        "  actor.update_target_network()\n",
        "\n",
        "  return np.amax(critic_Q_value), critic_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1OyZWy6OEB_"
      },
      "source": [
        "## **8. Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Using the train data to build and train a model**\n",
        "1. Parameters are trained\n",
        "2. Updation of the actor and critic network\n",
        "3. Saving the trained model\n"
      ],
      "metadata": {
        "id": "glTSEJktFpUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXLD3yFmOHwt"
      },
      "outputs": [],
      "source": [
        "class Noise:\n",
        "  ''' Noise for Actor predictions '''\n",
        "  def __init__(self, action_space_size, mu=0, theta=0.5, sigma=0.2):\n",
        "    self.action_space_size = action_space_size\n",
        "    self.mu = mu\n",
        "    self.theta = theta\n",
        "    self.sigma = sigma\n",
        "    self.state = np.ones(self.action_space_size) * self.mu\n",
        "\n",
        "  def get(self):\n",
        "    self.state += self.theta * (self.mu - self.state) + self.sigma * np.random.rand(self.action_space_size)\n",
        "    return self.state\n",
        "    \n",
        "\n",
        "def train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary):\n",
        "  \n",
        "  # Set up summary operators\n",
        "  def build_summaries():\n",
        "    episode_reward = tf.Variable(0.)\n",
        "    tf.summary.scalar('reward', episode_reward)\n",
        "    episode_max_Q = tf.Variable(0.)\n",
        "    tf.summary.scalar('max_Q_value', episode_max_Q)\n",
        "    critic_loss = tf.Variable(0.)\n",
        "    tf.summary.scalar('critic_loss', critic_loss)\n",
        "\n",
        "    summary_vars = [episode_reward, episode_max_Q, critic_loss]\n",
        "    summary_ops = tf.summary.merge_all()\n",
        "    return summary_ops, summary_vars\n",
        "\n",
        "  summary_ops, summary_vars = build_summaries()\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  writer = tf.summary.FileWriter(filename_summary, sess.graph)\n",
        "\n",
        "  # Initialize target network f′ and Q′\n",
        "  actor.init_target_network()\n",
        "  critic.init_target_network()\n",
        "\n",
        "  # Initialize the capacity of replay memory D\n",
        "  replay_memory = ReplayMemory(buffer_size) \n",
        "  replay = False\n",
        "\n",
        "\n",
        "  start_time = time.time()\n",
        "  for i_session in range(nb_episodes): \n",
        "    session_reward = 0\n",
        "    session_Q_value = 0\n",
        "    session_critic_loss = 0\n",
        "    #Initialize state s_0 from previous sessions\n",
        "    states = environment.reset() \n",
        "    \n",
        "    # Update average parameters every 10 episodes\n",
        "    if (i_session + 1) % 10 == 0: \n",
        "      environment.groups = environment.get_groups()\n",
        "      \n",
        "    exploration_noise = Noise(history_length * embeddings.size())\n",
        "\n",
        "    for t in range(nb_rounds): \n",
        "      # Stage 1: Transition Generating Stage\n",
        "\n",
        "      # Select an action a_t = {a_t^1, ..., a_t^K} \n",
        "      actions = actor.get_recommendation_list(\n",
        "          ra_length,\n",
        "          states.reshape(1, -1), \n",
        "          embeddings).reshape(ra_length, embeddings.size())\n",
        "\n",
        "      # Execute action a_t and observe the reward list {r_t^1, ..., r_t^K} for each item in a_t\n",
        "      rewards, next_states = environment.step(actions)\n",
        "\n",
        "      # Store transition (s_t, a_t, r_t, s_t+1) in D\n",
        "      replay_memory.add(states.reshape(history_length * embeddings.size()),\n",
        "                        actions.reshape(ra_length * embeddings.size()),\n",
        "                        [rewards],\n",
        "                        next_states.reshape(history_length * embeddings.size()))\n",
        "\n",
        "      # Set s_t = s_t+1\n",
        "      states = next_states \n",
        "\n",
        "      session_reward += rewards\n",
        "      \n",
        "      # Stage 2: Parameter Updating Stage\n",
        "      if replay_memory.size() >= batch_size: # Experience replay\n",
        "        replay = True\n",
        "        replay_Q_value, critic_loss = experience_replay(replay_memory, batch_size,\n",
        "          actor, critic, embeddings, ra_length, history_length * embeddings.size(),\n",
        "          ra_length * embeddings.size(), discount_factor)\n",
        "        session_Q_value += replay_Q_value\n",
        "        session_critic_loss += critic_loss\n",
        "\n",
        "      summary_str = sess.run(summary_ops,\n",
        "                             feed_dict={summary_vars[0]: session_reward,\n",
        "                                        summary_vars[1]: session_Q_value,\n",
        "                                        summary_vars[2]: session_critic_loss})\n",
        "      \n",
        "      writer.add_summary(summary_str, i_session)\n",
        "\n",
        "    str_loss = str('Loss=%0.4f' % session_critic_loss)\n",
        "    print(('Episode %d/%d Reward=%d Time=%ds ' + (str_loss if replay else 'No replay')) % (i_session + 1, nb_episodes, session_reward, time.time() - start_time))\n",
        "    start_time = time.time()\n",
        "\n",
        "  writer.close()\n",
        "  tf.train.Saver().save(sess, 'models.h5', write_meta_graph=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JmA3pQHOz5P",
        "outputId": "d2429bd1-d31d-4aef-b887-702a171ee9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "history_length = 12 # N in article\n",
        "ra_length = 4 # K in article\n",
        "discount_factor = 0.99 # Gamma in Bellman equation\n",
        "actor_lr = 0.0001\n",
        "critic_lr = 0.001\n",
        "tau = 0.001 # τ in Algorithm 3\n",
        "batch_size = 128\n",
        "nb_episodes = 5\n",
        "nb_rounds = 50\n",
        "filename_summary = 'summary.txt'\n",
        "alpha = 0.5 # α (alpha) in Equation (1)\n",
        "gamma = 0.9 # Γ (Gamma) in Equation (4)\n",
        "buffer_size = 1000000 # Size of replay memory D in article\n",
        "fixed_length = True # Fixed memory length\n",
        "\n",
        "dg = DataGenerator('ml-100k/u.data', 'ml-100k/u.item')\n",
        "dg.get_train_test_split(0.8, seed=42)\n",
        "\n",
        "dg.write_csv('train.csv', dg.train, nb_states=[history_length], nb_actions=[ra_length])\n",
        "dg.write_csv('test.csv', dg.test, nb_states=[history_length], nb_actions=[ra_length])\n",
        "\n",
        "data = file_reading('train.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6JzU_mMUO8XK",
        "outputId": "2df8dfdd-f446-471c-f3d4-6c9ebbe46f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "1/50\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 433us/step - loss: 6.9102 - accuracy: 0.0094 - val_loss: 6.5238 - val_accuracy: 0.0148\n",
            "2/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 357us/step - loss: 6.4546 - accuracy: 0.0128 - val_loss: 6.3460 - val_accuracy: 0.0166\n",
            "3/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 370us/step - loss: 6.2735 - accuracy: 0.0136 - val_loss: 6.2179 - val_accuracy: 0.0172\n",
            "4/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 349us/step - loss: 6.1904 - accuracy: 0.0152 - val_loss: 6.1344 - val_accuracy: 0.0168\n",
            "5/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 6.1735 - accuracy: 0.0178 - val_loss: 6.0598 - val_accuracy: 0.0174\n",
            "6/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 384us/step - loss: 6.1399 - accuracy: 0.0186 - val_loss: 6.0687 - val_accuracy: 0.0222\n",
            "7/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 359us/step - loss: 6.0296 - accuracy: 0.0188 - val_loss: 5.9727 - val_accuracy: 0.0234\n",
            "8/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 3s 586us/step - loss: 5.9926 - accuracy: 0.0238 - val_loss: 5.9617 - val_accuracy: 0.0266\n",
            "9/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 357us/step - loss: 5.9867 - accuracy: 0.0240 - val_loss: 5.9979 - val_accuracy: 0.0262\n",
            "10/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 352us/step - loss: 5.9462 - accuracy: 0.0248 - val_loss: 5.9386 - val_accuracy: 0.0264\n",
            "11/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 5.9308 - accuracy: 0.0242 - val_loss: 5.8121 - val_accuracy: 0.0324\n",
            "12/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 349us/step - loss: 5.9258 - accuracy: 0.0314 - val_loss: 5.8143 - val_accuracy: 0.0324\n",
            "13/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 350us/step - loss: 5.9174 - accuracy: 0.0280 - val_loss: 5.8317 - val_accuracy: 0.0380\n",
            "14/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 375us/step - loss: 5.8573 - accuracy: 0.0326 - val_loss: 5.7846 - val_accuracy: 0.0348\n",
            "15/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 5.8406 - accuracy: 0.0370 - val_loss: 5.7874 - val_accuracy: 0.0414\n",
            "16/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 364us/step - loss: 5.7904 - accuracy: 0.0368 - val_loss: 5.7221 - val_accuracy: 0.0450\n",
            "17/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 371us/step - loss: 5.8121 - accuracy: 0.0408 - val_loss: 5.7134 - val_accuracy: 0.0458\n",
            "18/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 373us/step - loss: 5.7680 - accuracy: 0.0402 - val_loss: 5.7200 - val_accuracy: 0.0408\n",
            "19/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 347us/step - loss: 5.8018 - accuracy: 0.0474 - val_loss: 5.6662 - val_accuracy: 0.0552\n",
            "20/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 354us/step - loss: 5.7161 - accuracy: 0.0418 - val_loss: 5.6428 - val_accuracy: 0.0546\n",
            "21/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 352us/step - loss: 5.6826 - accuracy: 0.0532 - val_loss: 5.6133 - val_accuracy: 0.0572\n",
            "22/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 362us/step - loss: 5.6762 - accuracy: 0.0562 - val_loss: 5.5849 - val_accuracy: 0.0622\n",
            "23/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 367us/step - loss: 5.6914 - accuracy: 0.0552 - val_loss: 5.5578 - val_accuracy: 0.0750\n",
            "24/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 5.6541 - accuracy: 0.0566 - val_loss: 5.5745 - val_accuracy: 0.0706\n",
            "25/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 5.6436 - accuracy: 0.0564 - val_loss: 5.5714 - val_accuracy: 0.0650\n",
            "26/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 372us/step - loss: 5.5728 - accuracy: 0.0674 - val_loss: 5.4641 - val_accuracy: 0.0720\n",
            "27/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 364us/step - loss: 5.5616 - accuracy: 0.0680 - val_loss: 5.4810 - val_accuracy: 0.0742\n",
            "28/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 359us/step - loss: 5.5369 - accuracy: 0.0728 - val_loss: 5.4454 - val_accuracy: 0.0874\n",
            "29/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 367us/step - loss: 5.4931 - accuracy: 0.0746 - val_loss: 5.4452 - val_accuracy: 0.0870\n",
            "30/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 374us/step - loss: 5.5206 - accuracy: 0.0722 - val_loss: 5.3742 - val_accuracy: 0.0920\n",
            "31/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 351us/step - loss: 5.4556 - accuracy: 0.0798 - val_loss: 5.3527 - val_accuracy: 0.0958\n",
            "32/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 360us/step - loss: 5.3690 - accuracy: 0.0904 - val_loss: 5.2991 - val_accuracy: 0.1064\n",
            "33/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 363us/step - loss: 5.3964 - accuracy: 0.0864 - val_loss: 5.2294 - val_accuracy: 0.1092\n",
            "34/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 360us/step - loss: 5.3655 - accuracy: 0.0888 - val_loss: 5.2164 - val_accuracy: 0.1192\n",
            "35/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 5.3477 - accuracy: 0.1036 - val_loss: 5.2097 - val_accuracy: 0.1230\n",
            "36/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 370us/step - loss: 5.2790 - accuracy: 0.1076 - val_loss: 5.1498 - val_accuracy: 0.1196\n",
            "37/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 369us/step - loss: 5.3034 - accuracy: 0.1068 - val_loss: 5.1928 - val_accuracy: 0.1258\n",
            "38/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 5.2617 - accuracy: 0.1112 - val_loss: 5.1329 - val_accuracy: 0.1250\n",
            "39/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 365us/step - loss: 5.1894 - accuracy: 0.1178 - val_loss: 5.0649 - val_accuracy: 0.1430\n",
            "40/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 5.1894 - accuracy: 0.1096 - val_loss: 5.0723 - val_accuracy: 0.1492\n",
            "41/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 357us/step - loss: 5.1812 - accuracy: 0.1166 - val_loss: 4.9935 - val_accuracy: 0.1458\n",
            "42/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 372us/step - loss: 5.1058 - accuracy: 0.1264 - val_loss: 4.9472 - val_accuracy: 0.1616\n",
            "43/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 5.0488 - accuracy: 0.1358 - val_loss: 4.9883 - val_accuracy: 0.1524\n",
            "44/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 364us/step - loss: 5.0288 - accuracy: 0.1374 - val_loss: 4.9527 - val_accuracy: 0.1652\n",
            "45/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 5.0087 - accuracy: 0.1432 - val_loss: 4.8975 - val_accuracy: 0.1744\n",
            "46/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 358us/step - loss: 4.9677 - accuracy: 0.1494 - val_loss: 4.8659 - val_accuracy: 0.1820\n",
            "47/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 355us/step - loss: 4.9112 - accuracy: 0.1586 - val_loss: 4.8145 - val_accuracy: 0.1904\n",
            "48/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 367us/step - loss: 4.9078 - accuracy: 0.1534 - val_loss: 4.8116 - val_accuracy: 0.1950\n",
            "49/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 362us/step - loss: 4.9281 - accuracy: 0.1594 - val_loss: 4.7362 - val_accuracy: 0.2186\n",
            "50/50\n",
            "Train on 5000 samples, validate on 5000 samples\n",
            "Epoch 1/1\n",
            "5000/5000 [==============================] - 2s 356us/step - loss: 4.8914 - accuracy: 0.1666 - val_loss: 4.6587 - val_accuracy: 0.2080\n",
            "100000/100000 [==============================] - 8s 82us/step\n",
            "Train set: Loss=4.7022 ; Accuracy=21.2%\n",
            "100000/100000 [==============================] - 8s 83us/step\n",
            "Test set: Loss=6.6883 ; Accuracy=4.8%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1af76d73-a0f9-41df-9a8a-86d02ad25ab8\", \"embeddings.csv\", 1911411)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "if True: # Generate embeddings?\n",
        "  eg = EmbeddingsGenerator(dg.user_train, pd.read_csv('ml-100k/u.data', sep='\\t', names=['userId', 'itemId', 'rating', 'timestamp']))\n",
        "  eg.train(nb_epochs=50)\n",
        "  train_loss, train_accuracy = eg.test(dg.user_train)\n",
        "  print('Train set: Loss=%.4f ; Accuracy=%.1f%%' % (train_loss, train_accuracy * 100))\n",
        "  test_loss, test_accuracy = eg.test(dg.user_test)\n",
        "  print('Test set: Loss=%.4f ; Accuracy=%.1f%%' % (test_loss, test_accuracy * 100))\n",
        "  eg.save_embeddings('embeddings.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F4DQ_F_PGTn",
        "outputId": "3c97867f-a8c0-4154-d334-66e3c3779448"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From <ipython-input-10-5ae0ce276ca1>:68: GRUCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.GRUCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-10-5ae0ce276ca1>:69: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/rnn_cell_impl.py:559: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From <ipython-input-10-5ae0ce276ca1>:40: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Episode 1/5 Reward=545 Time=4s No replay\n",
            "Episode 2/5 Reward=545 Time=4s No replay\n",
            "Episode 3/5 Reward=545 Time=57s Loss=1380.6227\n",
            "Episode 4/5 Reward=545 Time=118s Loss=108.8059\n",
            "Episode 5/5 Reward=545 Time=116s Loss=49.5759\n"
          ]
        }
      ],
      "source": [
        "embeddings = Embeddings(embeddings_reading('embeddings.csv'))\n",
        "\n",
        "state_space_size = embeddings.size() * history_length\n",
        "action_space_size = embeddings.size() * ra_length\n",
        "\n",
        "\n",
        "environment = Environment(data, embeddings, alpha, gamma, fixed_length)\n",
        "\n",
        "# For multiple consecutive executions\n",
        "tf.reset_default_graph() \n",
        "\n",
        "sess = tf.Session()\n",
        "# Initialize actor network f_θ^π and critic network Q(s, a|θ^µ) with random weights\n",
        "actor = Actor(sess, state_space_size, action_space_size, batch_size, ra_length, history_length, embeddings.size(), tau, actor_lr)\n",
        "critic = Critic(sess, state_space_size, action_space_size, history_length, embeddings.size(), tau, critic_lr)\n",
        "\n",
        "train(sess, environment, actor, critic, embeddings, history_length, ra_length, buffer_size, batch_size, discount_factor, nb_episodes, filename_summary)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xji6iig5OUrM"
      },
      "source": [
        "## **9. Testing**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Test on the Test dataset**\n",
        "\n",
        "1. Using the test dataset and movie embeddings saved previously\n",
        "2. Using the well trained parameters of the final model obtained"
      ],
      "metadata": {
        "id": "SsqWwgaDGNkc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n8Y9ggBQXIL"
      },
      "outputs": [],
      "source": [
        "dict_embeddings = {}\n",
        "for i, item in enumerate(embeddings.get_embedding_vector()):\n",
        "  str_item = str(item)\n",
        "  assert(str_item not in dict_embeddings)\n",
        "  dict_embeddings[str_item] = i\n",
        "\n",
        "def state_to_items(state, actor, ra_length, embeddings, dict_embeddings, target=False):\n",
        "  return [dict_embeddings[str(action)]\n",
        "          for action in actor.get_recommendation_list(ra_length, np.array(state).reshape(1, -1), embeddings, target).reshape(ra_length, embeddings.size())]\n",
        "\n",
        "def test_actor(actor, test_df, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1):\n",
        "  ratings = []\n",
        "  unknown = 0\n",
        "  random_seen = []\n",
        "  for _ in range(nb_rounds):\n",
        "    for i in range(len(test_df)):\n",
        "      history_sample = list(test_df[i].sample(history_length)['itemId'])\n",
        "      recommendation = state_to_items(embeddings.embed(history_sample), actor, ra_length, embeddings, dict_embeddings, target)\n",
        "      for item in recommendation:\n",
        "        l = list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])\n",
        "        assert(len(l) < 2)\n",
        "        if len(l) == 0:\n",
        "          unknown += 1\n",
        "        else:\n",
        "          ratings.append(l[0])\n",
        "      for item in history_sample:\n",
        "        random_seen.append(list(test_df[i].loc[test_df[i]['itemId'] == item]['rating'])[0])\n",
        "\n",
        "  return ratings, unknown, random_seen\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZqzMyXaQfMw"
      },
      "source": [
        "## **10. Performance Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jke7nJwMQ2wY"
      },
      "source": [
        "###**Train Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wey91-YREfu"
      },
      "source": [
        "Target = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV21TbBwQksO",
        "outputId": "7f62d9f6-2393-40ac-bab1-8c3bb73ecbb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.8% unknown\n"
          ]
        }
      ],
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=2)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison between the actual predictions made by the model and the randomly generated predictions"
      ],
      "metadata": {
        "id": "q3W8YBo2Id4N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQfvoaztQzvg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "ea42750f-eb03-438f-bf40-3887b5ead9b4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgtPZiWNQ5Wk"
      },
      "source": [
        "Target = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49JTyke9RIjO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d294edd-47ee-49a2-c882-4978ac181ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "86.8% unknown\n"
          ]
        }
      ],
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.train, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=2)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUO7hCL-RK2p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "8270fe39-bd8a-433a-d7b8-4ca916381115"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCr-wsFaRNEv"
      },
      "source": [
        "###**Test Set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MmfwzOPRX7h"
      },
      "source": [
        "Target = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bq5BYaz_RVu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73ec88f0-3197-4c07-9f2b-cfe88985955c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90.2% unknown\n"
          ]
        }
      ],
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=False, nb_rounds=1)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison between the actual predictions made by the model and the randomly generated predictions"
      ],
      "metadata": {
        "id": "9hEJ50TJInGV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7TKGTFEReZ_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "733b3928-3d18-4b8d-f15f-9a4b92e611dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLebjkR0RhgS"
      },
      "source": [
        "Target = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAzmOI0GRin-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d41d8cae-ad1e-4116-8fd1-8540045d8e8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "87.5% unknown\n"
          ]
        }
      ],
      "source": [
        "ratings, unknown, random_seen = test_actor(actor, dg.test, embeddings, dict_embeddings, ra_length, history_length, target=True, nb_rounds=2)\n",
        "print('%0.1f%% unknown' % (100 * unknown / (len(ratings) + unknown)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_whyIwm5RlCq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "4bf28f2d-8305-482e-a0b2-f331a76eb1eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(ratings)\n",
        "plt.title('Predictions ; Mean = %.4f' % (np.mean(ratings)))\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(random_seen)\n",
        "plt.title('Random ; Mean = %.4f' % (np.mean(random_seen)))\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_______________________________________________________"
      ],
      "metadata": {
        "id": "0OAYZHI1H1X7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u4lzk2hfJGZ0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}